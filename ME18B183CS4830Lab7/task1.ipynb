{"cells":[{"cell_type":"code","execution_count":4,"id":"3c8c5b9b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kafka-python\n","  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n","\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m246.5/246.5 KB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n","\u001B[?25hInstalling collected packages: kafka-python\n","Successfully installed kafka-python-2.0.2\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install kafka-python"]},{"cell_type":"code","execution_count":5,"id":"14940ce2","metadata":{},"outputs":[],"source":["import json\n","\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","\n","from __future__ import absolute_import\n","from kafka import KafkaProducer\n","\n","from time import sleep"]},{"cell_type":"code","execution_count":6,"id":"13d32741","metadata":{},"outputs":[],"source":["int_ip = '10.128.0.30:9092'               \n","topic = 'lab7topic'                   \n","file_path = 'gs://me18b183_bdl/lab7kafka/Iris.csv' "]},{"cell_type":"code","execution_count":7,"id":"5152d5fa","metadata":{},"outputs":[],"source":["producer = KafkaProducer(bootstrap_servers=[int_ip], value_serializer=lambda x: x.encode('utf-8'))"]},{"cell_type":"code","execution_count":8,"id":"91750247","metadata":{},"outputs":[],"source":["spark = SparkSession \\\n","    .builder \\\n","    .appName(\"lab7producer\") \\\n","    .getOrCreate()\n","\n","schema = StructType() \\\n","    .add(\"SepalLength\", FloatType()) \\\n","    .add(\"SepalWidth\", FloatType()) \\\n","    .add(\"PetalLength\", FloatType()) \\\n","    .add(\"PetalWidth\", FloatType()) \\\n","    .add(\"Species\", StringType())"]},{"cell_type":"code","execution_count":9,"id":"0f39921a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["Iris = spark.read.csv(file_path, header=True, schema=schema)\n","\n","for entry in Iris.toJSON().collect():\n","    producer.send(topic, value=entry)\n","    sleep(1)"]},{"cell_type":"code","execution_count":null,"id":"60ac4e90","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}