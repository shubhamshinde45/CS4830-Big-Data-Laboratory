{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 8**\n",
        "## Submitted by ME18B183- Shinde Shubham Sunil"
      ],
      "metadata": {
        "id": "KARAGCYBCUkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting started**"
      ],
      "metadata": {
        "id": "rBrzL5qSB846"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install openjdk-11-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uQGli7mrYdF",
        "outputId": "e6706594-7646-4c9e-fe04-cd0e0fefc7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-11-jdk is already the newest version (11.0.14.1+1-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do2zZnKZqbJa",
        "outputId": "de011497-2f73-485e-d03e-96e2403967da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.5)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (2.8.0.dev2021122109)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -q findspark\n",
        "!pip install pyarrow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-estimator-nightly==2.8.0.dev2021122109\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "PgSduGVLqh68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, pandas_udf, regexp_extract\n",
        "import io\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "vuhv8H3ltDPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading CIFAR10 dataset**"
      ],
      "metadata": {
        "id": "4VyDCOXlCFuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = tf.keras.utils.get_file(origin='http://pjreddie.com/media/files/cifar.tgz',\n",
        "                                         fname='cifar', untar=True)\n",
        "\n",
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3tL830JtGl4",
        "outputId": "cdc4da5d-83b0-47db-f0e2-b44b1c2a7770"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://pjreddie.com/media/files/cifar.tgz\n",
            "168584360/168584360 [==============================] - 14s 0us/step\n",
            "/root/.keras/datasets/cifar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = spark.read.format(\"binaryFile\").option(\"recursiveFileLookup\", \"true\").option(\"pathGlobFilter\", \"*.png\").load(data_dir)\n",
        "print(type(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJCP42qpu-Rb",
        "outputId": "0a80e2cd-a4d0-4e97-cc67-e5b666c15a5e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.show(5)"
      ],
      "metadata": {
        "id": "5sZHQHuAvGQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e57739a-bd0a-48a6-a355-8c164eb27bf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+------+--------------------+\n",
            "|                path|   modificationTime|length|             content|\n",
            "+--------------------+-------------------+------+--------------------+\n",
            "|file:/root/.keras...|2016-11-18 20:24:13|  3354|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:13|  3352|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:12|  3351|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:12|  3349|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:13|  3349|[89 50 4E 47 0D 0...|\n",
            "+--------------------+-------------------+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files=images.select('path').rdd.map(lambda x :x.path ).collect()\n",
        "files[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyDfhkhXzIcT",
        "outputId": "5337f3dc-4e4e-4448-e4d2-e27c1e033d36"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['file:/root/.keras/datasets/cifar/test/4672_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/test/8562_bird.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/10327_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/23455_deer.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/38450_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/29550_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/31532_bird.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/18370_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/test/6801_frog.png',\n",
              " 'file:/root/.keras/datasets/cifar/train/14628_frog.png']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_label(path_col):\n",
        "  \"\"\"Extract label from file path using built-in SQL functions.\"\"\"\n",
        "  return regexp_extract(path_col, \"_([^/.]+)\", 1)\n",
        "\n",
        "def extract_size(content):\n",
        "  \"\"\"Extract image size from its raw content.\"\"\"\n",
        "  image = Image.open(io.BytesIO(content))\n",
        "  return image.size\n",
        "\n",
        "@pandas_udf(\"width: int, height: int\")\n",
        "def extract_size_udf(content_series):\n",
        "  sizes = content_series.apply(extract_size)\n",
        "  return pd.DataFrame(list(sizes))\n",
        "\n",
        "df = images.select(\n",
        "  col(\"path\"),\n",
        "  col(\"modificationTime\"),\n",
        "  extract_label(col(\"path\")).alias(\"label\"),\n",
        "  extract_size_udf(col(\"content\")).alias(\"size\"),\n",
        "  col(\"content\"))\n",
        "\n",
        "\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csmol-EtzOCQ",
        "outputId": "4527d056-b16b-48d2-e212-5751f7277f9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-----+--------+--------------------+\n",
            "|                path|   modificationTime|label|    size|             content|\n",
            "+--------------------+-------------------+-----+--------+--------------------+\n",
            "|file:/root/.keras...|2016-11-18 20:24:13| frog|{32, 32}|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:13| bird|{32, 32}|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:12| frog|{32, 32}|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:12| deer|{32, 32}|[89 50 4E 47 0D 0...|\n",
            "|file:/root/.keras...|2016-11-18 20:24:13| frog|{32, 32}|[89 50 4E 47 0D 0...|\n",
            "+--------------------+-------------------+-----+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Dataset(Dataset):\n",
        "  \"\"\"\n",
        "  Converts image contents into a PyTorch Dataset with standard cifar10 preprocessing.\n",
        "  \"\"\"\n",
        "  def __init__(self, contents):\n",
        "    self.contents = contents\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.contents)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self._preprocess(self.contents[index])\n",
        "\n",
        "  def _preprocess(self, content):\n",
        "    image = Image.open(io.BytesIO(content))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    return transform(image)"
      ],
      "metadata": {
        "id": "nx2ISaoI0wdY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cifar10_model_udf(model_clf):\n",
        "\n",
        "  \"\"\"\n",
        "  Wraps an cifar10 model into a Pandas UDF that makes predictions.\n",
        "  \n",
        "  You might consider the following customizations for your own use case:\n",
        "    - Tune DataLoader's batch_size and num_workers for better performance.\n",
        "    - Use GPU for acceleration.\n",
        "    - Change prediction types.\n",
        "  \"\"\"\n",
        "\n",
        "  def predict(content_series_iter : pd.Series) -> pd.DataFrame:\n",
        "    model = model_clf()\n",
        "    model.eval()      \n",
        "    for content_series in content_series_iter:                                                    #Iterates overall all Images \n",
        "      dataset = CIFAR10Dataset(list(content_series))                                           \n",
        "      loader = DataLoader(dataset, batch_size=64) \n",
        "      with torch.no_grad():\n",
        "        for image_batch in loader:\n",
        "          predictions = model(image_batch).numpy()                                                # Predictions for all 1000 classes of Mobilenetv2 Training Dataset\n",
        "          predicted_labels = [x[0] for x in decode_predictions(predictions, top=1)]                       \n",
        "          yield pd.DataFrame(predicted_labels)\n",
        "    \n",
        "        \n",
        "  return_type = \"class: string, desc: string, score:float\"\n",
        "  return pandas_udf(return_type, PandasUDFType.SCALAR_ITER)(predict)   "
      ],
      "metadata": {
        "id": "dkpj622s8Kfg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG16 Classification model**"
      ],
      "metadata": {
        "id": "d7ROgwr6_LTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_udf = cifar10_model_udf(lambda: models.vgg16(pretrained=True))"
      ],
      "metadata": {
        "id": "XfWTlsvN9vZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b24965-d655-478f-8a98-ac4fcc96ec97"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  \"in the future releases. See SPARK-28264 for more details.\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = df.withColumn(\"prediction\", VGG16_udf(col(\"content\")))\n",
        "predictions.select(col(\"label\"),col(\"prediction\")).show(20, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8LBQoiE_Xue",
        "outputId": "b747a055-593a-45e8-e8e8-1fe7cd1e2cc4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------+\n",
            "|label|prediction                            |\n",
            "+-----+--------------------------------------+\n",
            "|frog |{n02130308, cheetah, 8.439269}        |\n",
            "|bird |{n02002724, black_stork, 5.3798957}   |\n",
            "|frog |{n01744401, rock_python, 6.444077}    |\n",
            "|deer |{n02114712, red_wolf, 5.7382617}      |\n",
            "|frog |{n02129165, lion, 7.53472}            |\n",
            "|frog |{n02128925, jaguar, 5.393148}         |\n",
            "|bird |{n01873310, platypus, 4.491262}       |\n",
            "|frog |{n01688243, frilled_lizard, 6.8681555}|\n",
            "|frog |{n02356798, fox_squirrel, 6.2243824}  |\n",
            "|frog |{n02114712, red_wolf, 8.19412}        |\n",
            "|deer |{n02356798, fox_squirrel, 9.399976}   |\n",
            "|bird |{n07248320, book_jacket, 4.6766686}   |\n",
            "|frog |{n02356798, fox_squirrel, 6.3912754}  |\n",
            "|frog |{n03447721, gong, 6.701816}           |\n",
            "|frog |{n02115913, dhole, 8.544827}          |\n",
            "|frog |{n02356798, fox_squirrel, 5.97714}    |\n",
            "|frog |{n02128385, leopard, 6.434851}        |\n",
            "|frog |{n02115913, dhole, 7.0508432}         |\n",
            "|frog |{n02356798, fox_squirrel, 7.0748363}  |\n",
            "|frog |{n02013706, limpkin, 6.339068}        |\n",
            "+-----+--------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet50 Classification model**"
      ],
      "metadata": {
        "id": "KIEBUe6F_7It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_udf = cifar10_model_udf(lambda: models.resnet50(pretrained=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14r_7nv4_ZA-",
        "outputId": "91d527e4-0909-4e26-c43d-588b923fad98"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  \"in the future releases. See SPARK-28264 for more details.\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = df.withColumn(\"prediction\", ResNet50_udf(col(\"content\")))\n",
        "predictions.select(col(\"label\"),col(\"prediction\")).show(20, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP7nwfXUAGg-",
        "outputId": "83085c1b-6312-4f09-befc-c5f3933d4430"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------------------------+\n",
            "|label|prediction                            |\n",
            "+-----+--------------------------------------+\n",
            "|frog |{n02130308, cheetah, 10.426459}       |\n",
            "|bird |{n01443537, goldfish, 6.834964}       |\n",
            "|frog |{n01496331, electric_ray, 7.9641924}  |\n",
            "|deer |{n04525038, velvet, 7.9794655}        |\n",
            "|frog |{n01688243, frilled_lizard, 7.3185043}|\n",
            "|frog |{n01496331, electric_ray, 7.7286572}  |\n",
            "|bird |{n02356798, fox_squirrel, 5.2075057}  |\n",
            "|frog |{n02356798, fox_squirrel, 8.57772}    |\n",
            "|frog |{n01644900, tailed_frog, 7.5442767}   |\n",
            "|frog |{n02129165, lion, 9.034145}           |\n",
            "|deer |{n02115913, dhole, 10.55313}          |\n",
            "|bird |{n02356798, fox_squirrel, 10.846921}  |\n",
            "|frog |{n02356798, fox_squirrel, 9.478152}   |\n",
            "|frog |{n01644900, tailed_frog, 10.755041}   |\n",
            "|frog |{n02356798, fox_squirrel, 10.489262}  |\n",
            "|frog |{n02356798, fox_squirrel, 8.230193}   |\n",
            "|frog |{n02002724, black_stork, 6.467869}    |\n",
            "|frog |{n02356798, fox_squirrel, 8.548313}   |\n",
            "|frog |{n02129165, lion, 6.934937}           |\n",
            "|frog |{n02119789, kit_fox, 6.5690036}       |\n",
            "+-----+--------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MobileNetV2 Classification model**"
      ],
      "metadata": {
        "id": "9hTiSxXXAXOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetV2_udf = cifar10_model_udf(lambda: models.mobilenet_v2(pretrained=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJYdfv9mAoOr",
        "outputId": "6922865b-0084-49f6-d8b0-9778ac819fb2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
            "  \"in the future releases. See SPARK-28264 for more details.\", UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = df.withColumn(\"prediction\", MobileNetV2_udf(col(\"content\")))\n",
        "predictions.select(col(\"label\"),col(\"prediction\")).show(20, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg6aWpQ_AxcJ",
        "outputId": "7f6df554-9c1f-4693-8337-2115728069d7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------------------------+\n",
            "|label|prediction                             |\n",
            "+-----+---------------------------------------+\n",
            "|frog |{n02356798, fox_squirrel, 7.4729676}   |\n",
            "|bird |{n02002724, black_stork, 8.031027}     |\n",
            "|frog |{n01744401, rock_python, 9.125906}     |\n",
            "|deer |{n02356798, fox_squirrel, 7.5615854}   |\n",
            "|frog |{n02457408, three-toed_sloth, 8.139731}|\n",
            "|frog |{n01756291, sidewinder, 6.910098}      |\n",
            "|bird |{n02002724, black_stork, 6.929695}     |\n",
            "|frog |{n03764736, milk_can, 9.065403}        |\n",
            "|frog |{n01688243, frilled_lizard, 9.57504}   |\n",
            "|frog |{n02119789, kit_fox, 10.592067}        |\n",
            "|deer |{n02422106, hartebeest, 9.47988}       |\n",
            "|bird |{n02606052, rock_beauty, 6.9106827}    |\n",
            "|frog |{n02325366, wood_rabbit, 6.7301545}    |\n",
            "|frog |{n01744401, rock_python, 7.9928703}    |\n",
            "|frog |{n02356798, fox_squirrel, 10.709429}   |\n",
            "|frog |{n02356798, fox_squirrel, 7.484116}    |\n",
            "|frog |{n01744401, rock_python, 7.1383753}    |\n",
            "|frog |{n02356798, fox_squirrel, 11.222729}   |\n",
            "|frog |{n02356798, fox_squirrel, 8.981187}    |\n",
            "|frog |{n01744401, rock_python, 7.793873}     |\n",
            "+-----+---------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}